{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "run.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9bhe4O20wC4",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xbTxvNyb3y2O",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir(\"./data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1Kj2BrCW1Ljs"
      },
      "source": [
        "###DATA UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w0ZImG-a03c-",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "def get_data_loaders(batch_size, num_clients, iid_split=True, percentage_val=0.2, full=False,\n",
        "                     non_iid_mix=0):\n",
        "    val_loader = None\n",
        "    train_input, train_target, test_input, test_target = load_data(flatten=False, full=full)\n",
        "    train_dataset = TensorDataset(train_input, train_target)\n",
        "\n",
        "    # If validation set is needed randomly split training set\n",
        "    if percentage_val:\n",
        "        val_dataset, train_dataset = torch.utils.data.random_split(train_dataset,\n",
        "                                                                   (int(percentage_val * len(train_dataset)),\n",
        "                                                                    int((1 - percentage_val) * len(train_dataset)))\n",
        "                                                                   )\n",
        "        val_loader = DataLoader(dataset=val_dataset,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=True)\n",
        "    # Split data for each client\n",
        "    if iid_split:\n",
        "        # Random IID data split\n",
        "        client_datasets = torch.utils.data.random_split(train_dataset, np.tile(int(len(train_dataset) / num_clients),\n",
        "                                                                               num_clients).tolist())\n",
        "    else:\n",
        "        if non_iid_mix:\n",
        "            non_iid_part, iid_part = get_non_iid_split(train_dataset, non_iid_mix)\n",
        "            client_datasets = get_non_iid_datasets(num_clients, non_iid_part)  # make client_datasets with non_iid_part\n",
        "            for client_nr, client_dataset in enumerate(client_datasets):\n",
        "                chunk_size = int(len(iid_part) / num_clients)\n",
        "                client_dataset.indices.\\\n",
        "                    extend(iid_part.indices[chunk_size*client_nr: chunk_size*(1+client_nr)])\n",
        "        else:\n",
        "            # Each client has different set of non overlapping digits\n",
        "            client_datasets = get_non_iid_datasets(num_clients, train_dataset)\n",
        "    random.shuffle(client_datasets)\n",
        "    train_loaders = []\n",
        "    for train_dataset in client_datasets:\n",
        "        train_loader = DataLoader(dataset=train_dataset,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True)\n",
        "        train_loaders.append(train_loader)\n",
        "\n",
        "    test_loader = DataLoader(dataset=TensorDataset(test_input, test_target),\n",
        "                             batch_size=batch_size)\n",
        "\n",
        "    return train_loaders, val_loader, test_loader\n",
        "\n",
        "\n",
        "def get_non_iid_split(train_dataset, non_iid_mix_p):\n",
        "    # split train_dataset into a non-iid and iid part\n",
        "    iid_part, non_iid_part = torch.utils.data.random_split(train_dataset, [round(non_iid_mix_p * len(train_dataset)),\n",
        "                                                                           round((1 - non_iid_mix_p) * len(\n",
        "                                                                               train_dataset))])\n",
        "    if isinstance(train_dataset, Subset):\n",
        "        iid_part.dataset = iid_part.dataset.dataset\n",
        "        non_iid_part.dataset = non_iid_part.dataset.dataset\n",
        "    return non_iid_part, iid_part\n",
        "\n",
        "\n",
        "def load_data(cifar=False, one_hot_labels=False, normalize=False, flatten=False, full=False):\n",
        "    data_dir = './data'\n",
        "\n",
        "    if cifar:\n",
        "        print('* Using CIFAR')\n",
        "        cifar_train_set = datasets.CIFAR10(data_dir + '/cifar10/', train=True, download=True)\n",
        "        cifar_test_set = datasets.CIFAR10(data_dir + '/cifar10/', train=False, download=True)\n",
        "\n",
        "        train_input = torch.from_numpy(cifar_train_set.data)\n",
        "        train_input = train_input.transpose(3, 1).transpose(2, 3).float()\n",
        "        train_target = torch.tensor(cifar_train_set.targets, dtype=torch.int64)\n",
        "\n",
        "        test_input = torch.from_numpy(cifar_test_set.data).float()\n",
        "        test_input = test_input.transpose(3, 1).transpose(2, 3).float()\n",
        "        test_target = torch.tensor(cifar_test_set.targets, dtype=torch.int64)\n",
        "\n",
        "    else:\n",
        "        print('* Using MNIST')\n",
        "        mnist_train_set = datasets.MNIST(data_dir + '/mnist/', train=True, download=True)\n",
        "        mnist_test_set = datasets.MNIST(data_dir + '/mnist/', train=False, download=True)\n",
        "\n",
        "        train_input = mnist_train_set.data.view(-1, 1, 28, 28).float()\n",
        "        train_target = mnist_train_set.targets\n",
        "        test_input = mnist_test_set.data.view(-1, 1, 28, 28).float()\n",
        "        test_target = mnist_test_set.targets\n",
        "\n",
        "    if flatten:\n",
        "        train_input = train_input.clone().reshape(train_input.size(0), -1)\n",
        "        test_input = test_input.clone().reshape(test_input.size(0), -1)\n",
        "\n",
        "    if not full:\n",
        "        print('** Reducing the data-set, (use --full for the full thing)')\n",
        "        train_input = train_input.narrow(0, 0, 5000)\n",
        "        train_target = train_target.narrow(0, 0, 5000)\n",
        "        test_input = test_input.narrow(0, 0, 5000)\n",
        "        test_target = test_target.narrow(0, 0, 5000)\n",
        "\n",
        "    print('** Use {:d} train and {:d} test samples'.format(train_input.size(0), test_input.size(0)))\n",
        "\n",
        "    if one_hot_labels:\n",
        "        train_target = convert_to_one_hot_labels(train_input, train_target)\n",
        "        test_target = convert_to_one_hot_labels(test_input, test_target)\n",
        "\n",
        "    if normalize:\n",
        "        mu, std = train_input.mean(), train_input.std()\n",
        "        train_input.sub_(mu).div_(std)\n",
        "        test_input.sub_(mu).div_(std)\n",
        "\n",
        "    return train_input, train_target, test_input, test_target\n",
        "\n",
        "\n",
        "def convert_to_one_hot_labels(input, target):\n",
        "    tmp = input.new_zeros(target.size(0), target.max() + 1)\n",
        "    tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
        "    return tmp\n",
        "\n",
        "\n",
        "def get_non_iid_datasets(num_clients, train_dataset):\n",
        "    \"\"\"\n",
        "    This function divides samples in a way that\n",
        "    each client has non-overlapping classes,\n",
        "    e.g client 1 has only digits 0 and 1 while client 2 has only digits 2 and 3.\n",
        "    To achieve this we perform binary search on labels tensor\n",
        "    to divide initial dataset\n",
        "    \"\"\"\n",
        "    client_datasets = []\n",
        "    # if we have validation set then train is a Subset type\n",
        "    if isinstance(train_dataset, Subset):\n",
        "        labels = train_dataset.dataset.tensors[1][train_dataset.indices]\n",
        "    else:\n",
        "        labels = train_dataset.tensors[1]\n",
        "    labels, sorted_indices = torch.sort(labels)\n",
        "    digits_per_client = 10 // num_clients\n",
        "    digit = 0\n",
        "    for client in range(num_clients):\n",
        "        first_idx = first_index(labels, 0, len(labels), digit)\n",
        "        if client == num_clients - 1:\n",
        "            last_idx = len(labels) - 1\n",
        "        else:\n",
        "            last_idx = last_index(labels, 0, len(labels), digit + (digits_per_client - 1))\n",
        "        if isinstance(train_dataset, Subset):\n",
        "            new_indices = np.array(train_dataset.indices)[sorted_indices[first_idx: last_idx + 1].numpy()]\n",
        "            client_dataset = Subset(train_dataset.dataset, new_indices.tolist())\n",
        "        else:\n",
        "            client_dataset = Subset(train_dataset, sorted_indices[first_idx: last_idx + 1].tolist())\n",
        "        client_datasets.append(client_dataset)\n",
        "        digit += digits_per_client\n",
        "    return client_datasets\n",
        "\n",
        "\n",
        "# binary search functions to retrieve first and last index of label in sorted labels array\n",
        "def first_index(array, low, high, item):\n",
        "    if high >= low:\n",
        "        mid = low + (high - low) // 2\n",
        "        if (mid == 0 or item > array[mid - 1]) and array[mid] == item:\n",
        "            return mid\n",
        "        elif item > array[mid]:\n",
        "            return first_index(array, (mid + 1), high, item)\n",
        "        else:\n",
        "            return first_index(array, low, (mid - 1), item)\n",
        "    print(f\"This label {item} was not found\")\n",
        "    return -1\n",
        "\n",
        "\n",
        "def last_index(array, low, high, item):\n",
        "    if high >= low:\n",
        "        mid = low + (high - low) // 2\n",
        "        if (mid == len(array) - 1 or item < array[mid + 1]) and array[mid] == item:\n",
        "            return mid\n",
        "        elif item < array[mid]:\n",
        "            return last_index(array, low, (mid - 1), item)\n",
        "        else:\n",
        "            return last_index(array, (mid + 1), high, item)\n",
        "    print(f\"This label {item} was not found\")\n",
        "    return -1\n",
        "\n",
        "\n",
        "def get_model_bits(state_dict):\n",
        "    \"\"\"\n",
        "    :param state_dict: model object for which we want to get size in bits\n",
        "    :return: model_size - number of bites for all model's parameters\n",
        "    \"\"\"\n",
        "    torch.save(state_dict, \"temp.p\")\n",
        "    # Multiply by 8 to go from bytes to bits\n",
        "    model_size = os.path.getsize(\"temp.p\") * 8\n",
        "    os.remove('temp.p')\n",
        "    return model_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ePo62fMS1TSp"
      },
      "source": [
        "###QUANTIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wdNFSP_G1SnU",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def quantize_float16(model_dict):\n",
        "    \"\"\"\n",
        "    :param model: Model's state dict with default 32-bit float parameters\n",
        "    :return: model's state dict with 16-bit float parameters\n",
        "    \"\"\"\n",
        "    for name, param in model_dict.items():\n",
        "        model_dict[name] = param.half()\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "def quantize_int8(model_dict):\n",
        "    # Find maximum parameter\n",
        "    max_param = 0\n",
        "    for name, param in model_dict.items():\n",
        "        new_max = param.abs().max()\n",
        "        if new_max > max_param:\n",
        "            max_param = new_max\n",
        "    # Scale the maximum value to the max of an int8\n",
        "    multiplier = 127 / max_param\n",
        "    for name, param in model_dict.items():\n",
        "        model_dict[name] = (param * multiplier).to(torch.int8)\n",
        "    return model_dict, multiplier\n",
        "\n",
        "\n",
        "def decode_quantized_model_int8(model_dict, multiplier):\n",
        "    for name, param in model_dict.items():\n",
        "        model_dict[name] = param.to(torch.float32) / multiplier\n",
        "    return model_dict\n",
        "\n",
        "\n",
        "def no_quantization(model_dict):\n",
        "    return model_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mjOT9RKT1lCt"
      },
      "source": [
        "###MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9qilPkNt1kqX",
        "colab": {}
      },
      "source": [
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "# https://arxiv.org/pdf/1602.05629.pdf\n",
        "# A CNN with two 5x5 convolution layers (the first with\n",
        "# 32 channels, the second with 64, each followed with 2x2\n",
        "# max pooling), a fully connected layer with 512 units and\n",
        "# ReLu activation, and a final softmax output layer (1,663,370\n",
        "# total parameters).\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 64, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4 * 4 * 64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1tONngmM1eyD"
      },
      "source": [
        "###TRAINING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2KCwK2211eIN",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class Client:\n",
        "    def __init__(self, data_loader, epochs=5):\n",
        "        self.data_loader = data_loader\n",
        "        self.epochs = epochs\n",
        "        self.lr = 0.001\n",
        "        self.log_interval = 5\n",
        "        self.seed = 42\n",
        "        torch.manual_seed(self.seed)\n",
        "        self.save_model = False\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = CNN().to(self.device)\n",
        "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
        "        self.gradient_compression = None\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.model_name = \"mnist_cnn\"\n",
        "\n",
        "\n",
        "def train(client, epoch, logging=True):\n",
        "    # put model in train mode, we need gradients\n",
        "    client.model.train()\n",
        "    train_loader = client.data_loader\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        client.optimizer.zero_grad()\n",
        "        output = client.model(data)\n",
        "        # get the basic loss for our main task\n",
        "        total_loss = client.criterion(output, target)\n",
        "        total_loss.backward()\n",
        "        train_loss += total_loss.item()\n",
        "        client.optimizer.step()\n",
        "    _, train_accuracy = test(client, logging=False)\n",
        "    if logging:\n",
        "        print(f'Train Epoch: {epoch} Loss: {total_loss.item():.6f}, Train accuracy: {train_accuracy}')\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def test(client, logging=True):\n",
        "    # put model in eval mode, disable dropout etc.\n",
        "    client.model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    test_loader = client.data_loader\n",
        "    # disable grad to perform testing quicker\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            data, target = data.to(client.device), target.to(client.device)\n",
        "            output = client.model(data)\n",
        "            test_loss += client.criterion(output, target).item()\n",
        "            # prediction is an output with maximal probability\n",
        "            pred = output.argmax(1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    if logging:\n",
        "        print(f'Test set: Average loss: {test_loss:.4f}, '\n",
        "              f'Test accuracy: {correct} / {len(test_loader.dataset)} '\n",
        "              f'({test_accuracy:.0f}%)\\n')\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "def average_client_models(clients_dicts):\n",
        "    \"\"\"\n",
        "    :param clients_dicts: list of clients state dicts\n",
        "    :return: state_dict of averaged parameters\n",
        "    \"\"\"\n",
        "    # To perform averaging we need to go back to float32 cause summing is not supported for float16\n",
        "    for client in clients_dicts:\n",
        "        for name, param in client.items():\n",
        "            client[name] = param.float()\n",
        "    dict_keys = clients_dicts[0].keys()\n",
        "    final_dict = dict.fromkeys(dict_keys)\n",
        "    for key in dict_keys:\n",
        "        # Average model parameters\n",
        "        final_dict[key] = torch.cat([dictionary[key].unsqueeze(0) for dictionary in clients_dicts], dim=0).sum(0).div(\n",
        "            len(clients_dicts))\n",
        "    return final_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6-wtjQX-1sWP"
      },
      "source": [
        "### EXPERIMENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kUJUI7iy16aG",
        "colab": {}
      },
      "source": [
        "# Create outputs directory when running in colab for the first time\n",
        "if not os.path.isdir(\"outputs\"):\n",
        "    os.mkdir(\"outputs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN_YQLX3TEC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_experiment(target_accuracy, iid_split, \n",
        "                   non_iid_mix, client_epochs, \n",
        "                   dir_name, quantization, percentage_val=0, \n",
        "                   full=True, num_clients=5, batch_size=25):\n",
        "\n",
        "  if not os.path.isdir(os.path.join(\"outputs\", dir_name)):\n",
        "    os.mkdir(os.path.join(\"outputs\", dir_name))\n",
        "\n",
        "  epochs_per_client = num_clients * [client_epochs]\n",
        "\n",
        "  # Load data\n",
        "  train_loaders, _, test_loader = get_data_loaders(batch_size, num_clients, non_iid_mix=non_iid_mix,\n",
        "                                                  percentage_val=percentage_val, iid_split=iid_split, full=full)\n",
        "\n",
        "  # Initialize all clients\n",
        "  clients = [Client(train_loader, epochs) for train_loader, epochs in zip(train_loaders, epochs_per_client)]\n",
        "\n",
        "  # Set seed for the script\n",
        "  torch.manual_seed(clients[0].seed)\n",
        "\n",
        "  testing_accuracy = 0\n",
        "  num_rounds = 1\n",
        "\n",
        "  central_server = Client(test_loader)\n",
        "\n",
        "  filename = f\"iid_split_{iid_split}_quantization_{quantization.__name__}_num_epochs_{client_epochs}_mix_{non_iid_mix}.pkl\"\n",
        "  experiment_state = {\"num_rounds\": 0,\n",
        "                      \"test_accuracies\": [],\n",
        "                      \"conserved_bits_from_server\": [],\n",
        "                      \"conserved_bits_from_clients\": [],\n",
        "                      \"transferred_bits_from_server\": [],\n",
        "                      \"transferred_bits_from_clients\": [],\n",
        "                      \"original_bits_from_server\": [],\n",
        "                      \"original_bits_from_clients\": []\n",
        "                      }\n",
        "\n",
        "  # Multiplier for int8 quantization\n",
        "  multiplier = 0\n",
        "\n",
        "  while testing_accuracy < target_accuracy:\n",
        "      print(\"Communication Round {0}\".format(num_rounds))\n",
        "\n",
        "      if num_rounds > 1:\n",
        "          # Load server weights onto clients\n",
        "          total_bits_conserved = 0\n",
        "          total_bits_transferred = 0\n",
        "          total_float_model_bits = 0\n",
        "          for client in clients:\n",
        "              with torch.no_grad():\n",
        "                  # Calculate number of bits in full server model\n",
        "                  float_model_bits = get_model_bits(central_server.model.state_dict())\n",
        "                  # Quantize server's model\n",
        "                  if quantization == quantize_int8:\n",
        "                      quantized_model, multiplier = quantization(central_server.model.state_dict())\n",
        "                  else:\n",
        "                      quantized_model = quantization(central_server.model.state_dict())\n",
        "                  bits_transferred = get_model_bits(quantized_model)\n",
        "                  # Calculate how many bits we saved\n",
        "                  bits_conserved = (float_model_bits - bits_transferred)\n",
        "                  # If quantization method is int8, decode the weights\n",
        "                  if quantization == quantize_int8:\n",
        "                      quantized_model = decode_quantized_model_int8(quantized_model, multiplier)\n",
        "                  # Distribute quantized model on clients\n",
        "                  client.model.load_state_dict(quantized_model)\n",
        "                  # Update summary values\n",
        "                  total_bits_conserved += bits_conserved\n",
        "                  total_bits_transferred += bits_transferred\n",
        "                  total_float_model_bits += float_model_bits\n",
        "\n",
        "          # Add to our summary\n",
        "          experiment_state[\"conserved_bits_from_server\"].append(total_bits_conserved // num_clients)\n",
        "          experiment_state[\"transferred_bits_from_server\"].append(total_bits_transferred // num_clients)\n",
        "          experiment_state[\"original_bits_from_server\"].append(total_float_model_bits // num_clients)\n",
        "\n",
        "      # Perform E local training steps for each client\n",
        "      for client_idx, client in enumerate(clients):\n",
        "          print(\"Training client {0}\".format(client_idx))\n",
        "          for epoch in range(1, client.epochs + 1):\n",
        "              train(client, epoch)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          # Get number of bits in all clients' models before quantization\n",
        "          clients_bits = reduce((lambda x, y: x + y), [get_model_bits(client.model.state_dict()) for client in clients])\n",
        "          # Quantize clients models\n",
        "          if quantization == quantize_int8:\n",
        "              quantized_clients_models = []\n",
        "              multipliers = []\n",
        "              for client in clients:\n",
        "                  client_model, multiplier = quantization(client.model.state_dict())\n",
        "                  quantized_clients_models.append(client_model)\n",
        "                  multipliers.append(multiplier)\n",
        "          else:\n",
        "              quantized_clients_models = [quantization(client.model.state_dict()) for client in clients]\n",
        "          quantized_clients_bits = reduce((lambda x, y: x + y),\n",
        "                                          [get_model_bits(client) for client in quantized_clients_models])\n",
        "          bits_conserved = (clients_bits - quantized_clients_bits) // num_clients\n",
        "          # Add to summary\n",
        "          experiment_state[\"conserved_bits_from_clients\"].append(bits_conserved)\n",
        "          experiment_state[\"transferred_bits_from_clients\"].append(quantized_clients_bits // num_clients)\n",
        "          experiment_state[\"original_bits_from_clients\"].append(clients_bits // num_clients)\n",
        "          # Decode bits on central server side:\n",
        "          if quantization == quantize_int8:\n",
        "              new_client_models = []\n",
        "              for client, multiplier in zip(quantized_clients_models, multipliers):\n",
        "                  new_client = decode_quantized_model_int8(client, multiplier)\n",
        "                  new_client_models.append(new_client)\n",
        "              quantized_clients_models = new_client_models\n",
        "          # Send quantized models to server and average them\n",
        "          averaged_model = average_client_models(quantized_clients_models)\n",
        "          central_server.model.load_state_dict(averaged_model)\n",
        "      # We have to convert back to float32 otherwise there is a mismatch with input dtype\n",
        "      central_server.model.to(torch.float32)\n",
        "      # Test the aggregated model\n",
        "      test_loss, testing_accuracy = test(central_server)\n",
        "      experiment_state['test_accuracies'].append(testing_accuracy)\n",
        "      experiment_state['num_rounds'] = num_rounds + 1\n",
        "      \n",
        "      # Save experiment states\n",
        "      with open(os.path.join(\"./outputs\", dir_name, filename), \"wb\") as f:\n",
        "          pickle.dump(experiment_state, f)\n",
        "      \n",
        "      num_rounds += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yLhdO_zY1gy1",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "from functools import reduce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOvuuy77gyDx",
        "colab_type": "text"
      },
      "source": [
        "## EXPERIMENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZZ4wRlBfjy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IID\n",
        "for quantization in [no_quantization, quantize_float16, quantize_int8]:\n",
        "  for client_epochs in [1, 5, 10, 20]:\n",
        "    run_experiment(client_epochs=client_epochs, quantization=quantization,\n",
        "                   target_accuracy=99, iid_split=True, \n",
        "                   non_iid_mix=0, dir_name=\"iid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_7-67CsgPws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mix 5% IID\n",
        "for quantization in [no_quantization, quantize_float16, quantize_int8]:\n",
        "  for client_epochs in [1, 5, 10, 20]:\n",
        "    run_experiment(client_epochs=client_epochs, quantization=quantization,\n",
        "                   target_accuracy=98, iid_split=False,\n",
        "                   non_iid_mix=0.05, dir_name=\"mix\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib0zi6aTgOgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# non-IID\n",
        "for quantization in [quantize_float16, quantize_int8]:\n",
        "  for client_epochs in [20]:\n",
        "    run_experiment(client_epochs=client_epochs, quantization=quantization,\n",
        "                   target_accuracy=93, iid_split=False, \n",
        "                   non_iid_mix=0, dir_name=\"non_iid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxNN_SEyg2GQ",
        "colab_type": "text"
      },
      "source": [
        "## PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnApzehNnNEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iid_dir = os.path.join(\"/content\", \"outputs\" ,\"iid\")\n",
        "non_iid_dir = os.path.join(\"/content\", \"outputs\" ,\"non_iid\")\n",
        "mix_dir = os.path.join(\"/content\", \"outputs\" ,\"mix\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JpsUtZzWWsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYeu2g9Zi2NC",
        "colab_type": "text"
      },
      "source": [
        "figure 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4dlrq06gwH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filename in os.listdir(iid_dir):\n",
        "    if (\"no_quantization\" in filename) and (\"num_epochs_1_\" in filename):\n",
        "        with open(os.path.join(iid_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        iid = exp['test_accuracies']\n",
        "\n",
        "for filename in os.listdir(non_iid_dir):\n",
        "    if (\"no_quantization\" in filename) and (\"num_epochs_1_\" in filename):\n",
        "        with open(os.path.join(non_iid_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        non_iid = exp['test_accuracies']\n",
        "\n",
        "for filename in os.listdir(mix_dir):\n",
        "    if (\"no_quantization\" in filename) and (\"num_epochs_1_\" in filename):\n",
        "        with open(os.path.join(mix_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        mix = exp['test_accuracies']\n",
        "\n",
        "\n",
        "plt.plot(non_iid[:21], label=\"non-IID\")\n",
        "plt.plot(mix[:21], label=\"non-IID with 5% IID\")\n",
        "plt.plot(iid, label=\"IID\")\n",
        "plt.legend()\n",
        "plt.xticks(list(range(21)), list(range(1, 22)))\n",
        "plt.xlabel(\"Communication round\")\n",
        "plt.ylabel(\"Test accuracy (%)\")\n",
        "plt.title(\"Test accuracies for different data distribution methods\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5453txHri_-K",
        "colab_type": "text"
      },
      "source": [
        "figure 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zd801doi3aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# no quantization\n",
        "labels = [\"E=1\", \"E=5\", \"E=10\", \"E=20\"]\n",
        "\n",
        "iid = {}\n",
        "non_iid = {}\n",
        "mix = {}\n",
        "\n",
        "for filename in os.listdir(iid_dir):\n",
        "    if (\"no_quantization\" in filename):\n",
        "        num_epochs = int(filename[:-3].split(\"_\")[-3])\n",
        "        with open(os.path.join(iid_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        iid[num_epochs] = exp[\"num_rounds\"]\n",
        "\n",
        "for filename in os.listdir(non_iid_dir):\n",
        "    if (\"no_quantization\" in filename):\n",
        "        num_epochs = int(filename[:-3].split(\"_\")[-3])\n",
        "        with open(os.path.join(non_iid_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        non_iid[num_epochs] = exp[\"num_rounds\"]\n",
        "\n",
        "for filename in os.listdir(mix_dir):\n",
        "    if (\"no_quantization\" in filename):\n",
        "        num_epochs = int(filename[:-3].split(\"_\")[-3])\n",
        "        with open(os.path.join(mix_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        mix[num_epochs] = exp[\"num_rounds\"]\n",
        "\n",
        "iid = [v for (_, v) in iid.items()]\n",
        "non_iid = [v for (_, v) in non_iid.items()]\n",
        "mix = [v for (_, v) in mix.items()]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the barsiid = [v for (_, v) in iid.items()]\n",
        "\n",
        "fig, (ax, ax1) = plt.subplots(2, 1, figsize=(6.4, 5))\n",
        "\n",
        "rects1 = ax.bar(x - width/2, non_iid, width, label='non-IID', align='center')\n",
        "rects2 = ax.bar(x + width/2, mix, width, label='non-IID with 5% IID', align='center')\n",
        "rects3 = ax.bar(x + 1.5*width, iid, width, label='IID', align='center')\n",
        "\n",
        "ax.set_ylim([0, 45])\n",
        "ax1.set_ylim([0, 45])\n",
        "\n",
        "\n",
        "# float16\n",
        "labels = [\"E=1\", \"E=5\", \"E=10\", \"E=20\"]\n",
        "\n",
        "iid = {}\n",
        "non_iid = {}\n",
        "mix = {}\n",
        "\n",
        "for filename in os.listdir(iid_dir):\n",
        "    if (\"float16\" in filename):\n",
        "        num_epochs = int(filename[:-3].split(\"_\")[-3])\n",
        "        with open(os.path.join(iid_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        iid[num_epochs] = exp[\"num_rounds\"]\n",
        "\n",
        "for filename in os.listdir(non_iid_dir):\n",
        "    if (\"float16\" in filename):\n",
        "        num_epochs = int(filename[:-3].split(\"_\")[-3])\n",
        "        with open(os.path.join(non_iid_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        non_iid[num_epochs] = exp[\"num_rounds\"]\n",
        "\n",
        "for filename in os.listdir(mix_dir):\n",
        "    if (\"float16\" in filename):\n",
        "        num_epochs = int(filename[:-3].split(\"_\")[-3])\n",
        "        with open(os.path.join(mix_dir, filename), \"rb\") as f:\n",
        "            exp = pickle.load(f)\n",
        "        mix[num_epochs] = exp[\"num_rounds\"]\n",
        "\n",
        "iid = [v for (_, v) in iid.items()]\n",
        "non_iid = [v for (_, v) in non_iid.items()]\n",
        "mix = [v for (_, v) in mix.items()]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "\n",
        "rects4 = ax1.bar(x - width/2, non_iid, width, label='non-IID', align='center')\n",
        "rects5 = ax1.bar(x + width/2, mix, width, label='non-IID with 5% IID', align='center')\n",
        "rects6 = ax1.bar(x + 1.5*width, iid, width, label='IID', align='center')\n",
        "\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "fig.text(0.015, 0.5, 'Number of communication rounds', ha='center', va='center', rotation='vertical')\n",
        "\n",
        "ax.set_title('No quantization')\n",
        "ax1.set_title('Float16 quantization')\n",
        "ax.set_xticks(x)\n",
        "ax1.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax1.set_xticklabels(labels)\n",
        "\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "fig.legend(handles, labels, bbox_to_anchor=(1, 1))\n",
        "\n",
        "def autolabel(rects, ax):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1, ax)\n",
        "autolabel(rects2, ax)\n",
        "autolabel(rects3, ax)\n",
        "\n",
        "autolabel(rects4, ax1)\n",
        "autolabel(rects5, ax1)\n",
        "autolabel(rects6, ax1)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGinCdLjk51Q",
        "colab_type": "text"
      },
      "source": [
        "figure 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xlKQFxOmDNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_bits_data(quantization):\n",
        "  iid = {}\n",
        "  non_iid = {}\n",
        "  mix = {}\n",
        "  distribution_dicts = []\n",
        "\n",
        "  for dir_name in [iid_dir, non_iid_dir, mix_dir]:\n",
        "    distribution_dict = {}\n",
        "    for filename in os.listdir(dir_name):\n",
        "        if (quantization in filename):\n",
        "            num_epochs = int(filename[:-3].split(\"_\")[-3])\n",
        "            with open(os.path.join(dir_name, filename), \"rb\") as f:\n",
        "                exp = pickle.load(f)\n",
        "            distribution_dict[num_epochs] = sum(exp[\"transferred_bits_from_server\"]) + sum(exp[\"transferred_bits_from_clients\"])\n",
        "    distribution_dicts.append(distribution_dict)\n",
        "\n",
        "  iid_bits = [v for (_, v) in distribution_dicts[0].items()]\n",
        "  non_iid_bits = [v for (_, v) in distribution_dicts[1].items()]\n",
        "  mix_bits = [v for (_, v) in distribution_dicts[2].items()]\n",
        "\n",
        "  return iid_bits, non_iid_bits, mix_bits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqNU8S44nuSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nq_iid_bits, nq_non_iid_bits, nq_mix_bits = extract_bits_data(\"no_quantization\")\n",
        "\n",
        "fl_iid_bits, fl_non_iid_bits, fl_mix_bits = extract_bits_data(\"float16\")\n",
        "\n",
        "iid_bits = nq_iid_bits + fl_iid_bits\n",
        "non_iid_bits = nq_non_iid_bits + fl_non_iid_bits\n",
        "mix_bits = nq_mix_bits + fl_mix_bits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT7vs-qIk5VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iid_mgbits = [bits/1000000 for bits in iid_bits]\n",
        "non_iid_mgbits = [bits/1000000 for bits in non_iid_bits]\n",
        "mix_mgbits = [bits/1000000 for bits in mix_bits]\n",
        "\n",
        "iid_mgbits = list(map(round, iid_mgbits))\n",
        "mix_mgbits = list(map(round, mix_mgbits))\n",
        "non_iid_mgbits = list(map(round, non_iid_mgbits))\n",
        "\n",
        "plt.plot(non_iid_mgbits, label=\"non-IID\")\n",
        "plt.plot(mix_mgbits, label=\"5% mix\")\n",
        "plt.plot(iid_mgbits, label=\"IID\")\n",
        "plt.yscale(\"log\")\n",
        "plt.xticks(np.arange(7), ['E=1 \\n no quantization', 'E=5', 'E=10', 'E=20', 'E=1 \\n float16 ', 'E=5', 'E=10', 'E=20'])\n",
        "plt.ylabel(\"Number of sent megabits\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "labels = [\"E=1 \\n no quantization \", \"E=5 \", \"E=10\", \"E=20\",\n",
        "          \"E=1 \\n float16\", \"E=5\", \"E=10\", \"E=20\"]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "rects1 = ax.bar(x - width/2, non_iid_mgbits, width, label='non-IID', align='center')\n",
        "rects2 = ax.bar(x + width/2, mix_mgbits, width, label='5% mix', align='center')\n",
        "rects3 = ax.bar(x + 1.5*width, iid_mgbits, width, label='IID', align='center')\n",
        "\n",
        "ax.set_yscale('log')\n",
        "ax.set_ylim(ymax=2000)\n",
        "\n",
        "ax.set_ylabel(\"Number of sent megabits\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "fig.legend(handles, labels, bbox_to_anchor=(1, 1.01))\n",
        "\n",
        "\n",
        "autolabel(rects1, ax)\n",
        "autolabel(rects2, ax)\n",
        "autolabel(rects3, ax)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}