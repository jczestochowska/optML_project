{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 2\n",
    "ACCURACY_THRESHOLD = 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 5000 train and 5000 test samples\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x181abfc8330>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "train_loaders, val_loader, test_loader = get_data_loaders(BATCH_SIZE, NUM_CLIENTS)\n",
    "print(len(train_loaders))\n",
    "\n",
    "#Initialize all clients\n",
    "clients = []\n",
    "for train_loader in train_loaders:\n",
    "    client = Client(train_loader)\n",
    "    clients.append(client)\n",
    "torch.manual_seed(clients[0].seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication Round 1\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.523767, Train accuracy: 87.55\n",
      "Train Epoch: 2 Loss: 0.211090, Train accuracy: 92.5\n",
      "Train Epoch: 3 Loss: 0.146634, Train accuracy: 94.75\n",
      "Train Epoch: 4 Loss: 0.259047, Train accuracy: 96.85\n",
      "Train Epoch: 5 Loss: 0.082258, Train accuracy: 98.0\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.545741, Train accuracy: 84.35\n",
      "Train Epoch: 2 Loss: 0.445594, Train accuracy: 91.35\n",
      "Train Epoch: 3 Loss: 0.353354, Train accuracy: 95.15\n",
      "Train Epoch: 4 Loss: 0.109376, Train accuracy: 96.35\n",
      "Train Epoch: 5 Loss: 0.153142, Train accuracy: 98.15\n",
      "Test set: Average loss: 0.0398, Test accuracy: 1479 / 5000 (30%)\n",
      "\n",
      "Communication Round 2\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.464770, Train accuracy: 88.95\n",
      "Train Epoch: 2 Loss: 0.211386, Train accuracy: 92.55\n",
      "Train Epoch: 3 Loss: 0.169998, Train accuracy: 95.1\n",
      "Train Epoch: 4 Loss: 0.094199, Train accuracy: 96.0\n",
      "Train Epoch: 5 Loss: 0.233825, Train accuracy: 95.7\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.434582, Train accuracy: 89.6\n",
      "Train Epoch: 2 Loss: 0.419808, Train accuracy: 91.9\n",
      "Train Epoch: 3 Loss: 0.213887, Train accuracy: 94.6\n",
      "Train Epoch: 4 Loss: 0.194580, Train accuracy: 96.1\n",
      "Train Epoch: 5 Loss: 0.287402, Train accuracy: 95.15\n",
      "Test set: Average loss: 0.0059, Test accuracy: 4525 / 5000 (90%)\n",
      "\n",
      "Communication Round 3\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.116762, Train accuracy: 96.4\n",
      "Train Epoch: 2 Loss: 0.092339, Train accuracy: 96.4\n",
      "Train Epoch: 3 Loss: 0.102193, Train accuracy: 97.2\n",
      "Train Epoch: 4 Loss: 0.129789, Train accuracy: 97.55\n",
      "Train Epoch: 5 Loss: 0.086150, Train accuracy: 97.95\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.183821, Train accuracy: 96.35\n",
      "Train Epoch: 2 Loss: 0.150951, Train accuracy: 97.2\n",
      "Train Epoch: 3 Loss: 0.099365, Train accuracy: 97.15\n",
      "Train Epoch: 4 Loss: 0.170489, Train accuracy: 98.25\n",
      "Train Epoch: 5 Loss: 0.085883, Train accuracy: 98.5\n",
      "Test set: Average loss: 0.0040, Test accuracy: 4679 / 5000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_accuracy = 0\n",
    "bits_transferred = 0\n",
    "num_rounds = 0\n",
    "bits_conserved = 0\n",
    "\n",
    "centralServer = Client(test_loader)\n",
    "\n",
    "while testing_accuracy < ACCURACY_THRESHOLD:\n",
    "    num_rounds += 1\n",
    "    print(\"Communication Round {0}\".format(num_rounds))\n",
    "    \n",
    "    if num_rounds > 1:\n",
    "        #Load server weights onto clients\n",
    "        #TODO: Count number of transferred bits\n",
    "        for client in clients:\n",
    "            with torch.no_grad():\n",
    "                client.model.load_state_dict(dict(centralServer.model.named_parameters()))\n",
    "                \n",
    "    #Perform E local training steps for each client\n",
    "    for client_idx, client in enumerate(clients):\n",
    "        print(\"Training client {0}\".format(client_idx))\n",
    "        for epoch in range(1, client.epochs + 1):\n",
    "            train(client, epoch)\n",
    "\n",
    "    #Average model parameters and test\n",
    "    #TODO: Count number of transfered bits and sparsify gradients\n",
    "    with torch.no_grad():\n",
    "        dict_params = averageClientModels(clients)\n",
    "        centralServer.model.load_state_dict(dict_params)\n",
    "    test_loss, testing_accuracy = test(centralServer)\n",
    "\n",
    "#Save model\n",
    "if centralServer.save_model:\n",
    "     torch.save(centralServer.model.state_dict(), f\"{centralServer.model_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
