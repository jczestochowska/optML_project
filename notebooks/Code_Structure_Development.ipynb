{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import project_path\n",
    "from training import *\n",
    "from data_utils import get_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 5\n",
    "ACCURACY_THRESHOLD = 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reducing the data-set, (use --full for the full thing)\n",
      "** Use 5000 train and 5000 test samples\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f807c2c3cd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "train_loaders, _, test_loader = get_data_loaders(BATCH_SIZE, NUM_CLIENTS, percentage_val=0.2, iid_split=False)\n",
    "print(len(train_loaders))\n",
    "\n",
    "#Initialize all clients\n",
    "clients = []\n",
    "for train_loader in train_loaders:\n",
    "    client = Client(train_loader)\n",
    "    clients.append(client)\n",
    "torch.manual_seed(clients[0].seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication Round 1\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.044400, Train accuracy: 97.70114942528735\n",
      "Train Epoch: 2 Loss: 0.026691, Train accuracy: 98.74608150470219\n",
      "Train Epoch: 3 Loss: 0.007348, Train accuracy: 99.16405433646813\n",
      "Train Epoch: 4 Loss: 0.011483, Train accuracy: 99.68652037617555\n",
      "Train Epoch: 5 Loss: 0.003100, Train accuracy: 100.0\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.012312, Train accuracy: 99.4291151284491\n",
      "Train Epoch: 2 Loss: 0.001269, Train accuracy: 99.61941008563274\n",
      "Train Epoch: 3 Loss: 0.000596, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 4 Loss: 0.001286, Train accuracy: 100.0\n",
      "Train Epoch: 5 Loss: 0.000018, Train accuracy: 100.0\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.000000, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 2 Loss: 0.076870, Train accuracy: 99.61612284069098\n",
      "Train Epoch: 3 Loss: 0.000004, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.000086, Train accuracy: 100.0\n",
      "Train Epoch: 5 Loss: 0.000000, Train accuracy: 100.0\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.041300, Train accuracy: 97.75739041794088\n",
      "Train Epoch: 2 Loss: 0.131751, Train accuracy: 98.47094801223241\n",
      "Train Epoch: 3 Loss: 0.040026, Train accuracy: 98.87869520897044\n",
      "Train Epoch: 4 Loss: 0.030601, Train accuracy: 99.38837920489297\n",
      "Train Epoch: 5 Loss: 0.009207, Train accuracy: 99.59225280326197\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.104652, Train accuracy: 98.45201238390094\n",
      "Train Epoch: 2 Loss: 0.073460, Train accuracy: 98.86480908152735\n",
      "Train Epoch: 3 Loss: 0.026707, Train accuracy: 99.69040247678019\n",
      "Train Epoch: 4 Loss: 0.006447, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 5 Loss: 0.042835, Train accuracy: 99.69040247678019\n",
      "Test set: Average loss: 0.0461, Test accuracy: 359 / 5000 (7%)\n",
      "\n",
      "Communication Round 2\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.979813, Train accuracy: 60.083594566353185\n",
      "Train Epoch: 2 Loss: 0.467233, Train accuracy: 91.0135841170324\n",
      "Train Epoch: 3 Loss: 0.198720, Train accuracy: 91.0135841170324\n",
      "Train Epoch: 4 Loss: 0.159417, Train accuracy: 93.31243469174504\n",
      "Train Epoch: 5 Loss: 0.112690, Train accuracy: 94.8798328108673\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.565281, Train accuracy: 47.66888677450048\n",
      "Train Epoch: 2 Loss: 0.175080, Train accuracy: 91.8173168411037\n",
      "Train Epoch: 3 Loss: 0.011520, Train accuracy: 98.57278782112274\n",
      "Train Epoch: 4 Loss: 0.147397, Train accuracy: 88.39200761179829\n",
      "Train Epoch: 5 Loss: 0.000757, Train accuracy: 98.95337773549001\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.209530, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 2 Loss: 0.044132, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 3 Loss: 0.012253, Train accuracy: 99.61612284069098\n",
      "Train Epoch: 4 Loss: 0.012762, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 5 Loss: 0.015004, Train accuracy: 99.71209213051823\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 2.281917, Train accuracy: 37.920489296636084\n",
      "Train Epoch: 2 Loss: 0.908620, Train accuracy: 67.2782874617737\n",
      "Train Epoch: 3 Loss: 0.582783, Train accuracy: 56.269113149847094\n",
      "Train Epoch: 4 Loss: 0.451374, Train accuracy: 72.27319062181448\n",
      "Train Epoch: 5 Loss: 0.178847, Train accuracy: 94.59734964322121\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 1.520403, Train accuracy: 55.21155830753354\n",
      "Train Epoch: 2 Loss: 0.521412, Train accuracy: 55.21155830753354\n",
      "Train Epoch: 3 Loss: 0.543821, Train accuracy: 82.6625386996904\n",
      "Train Epoch: 4 Loss: 0.069668, Train accuracy: 98.45201238390094\n",
      "Train Epoch: 5 Loss: 0.059218, Train accuracy: 98.45201238390094\n",
      "Test set: Average loss: 0.0436, Test accuracy: 977 / 5000 (20%)\n",
      "\n",
      "Communication Round 3\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.475804, Train accuracy: 68.3385579937304\n",
      "Train Epoch: 2 Loss: 0.109954, Train accuracy: 94.8798328108673\n",
      "Train Epoch: 3 Loss: 0.187139, Train accuracy: 77.22048066875654\n",
      "Train Epoch: 4 Loss: 0.058721, Train accuracy: 96.44723092998954\n",
      "Train Epoch: 5 Loss: 0.084104, Train accuracy: 95.5067920585162\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.060447, Train accuracy: 98.3824928639391\n",
      "Train Epoch: 2 Loss: 0.075997, Train accuracy: 98.47764034253092\n",
      "Train Epoch: 3 Loss: 0.012679, Train accuracy: 98.76308277830637\n",
      "Train Epoch: 4 Loss: 0.093688, Train accuracy: 95.33777354900096\n",
      "Train Epoch: 5 Loss: 0.001083, Train accuracy: 99.14367269267365\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.030085, Train accuracy: 99.61612284069098\n",
      "Train Epoch: 2 Loss: 0.024012, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 3 Loss: 0.026606, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 4 Loss: 0.007820, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 5 Loss: 0.002751, Train accuracy: 99.71209213051823\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.359773, Train accuracy: 88.58307849133537\n",
      "Train Epoch: 2 Loss: 0.142378, Train accuracy: 92.66055045871559\n",
      "Train Epoch: 3 Loss: 0.175852, Train accuracy: 95.92252803261978\n",
      "Train Epoch: 4 Loss: 0.107258, Train accuracy: 93.78185524974516\n",
      "Train Epoch: 5 Loss: 0.072559, Train accuracy: 96.73802242609582\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.251548, Train accuracy: 95.45923632610939\n",
      "Train Epoch: 2 Loss: 0.220427, Train accuracy: 94.53044375644996\n",
      "Train Epoch: 3 Loss: 0.144677, Train accuracy: 96.59442724458205\n",
      "Train Epoch: 4 Loss: 0.018319, Train accuracy: 98.65841073271415\n",
      "Train Epoch: 5 Loss: 0.025031, Train accuracy: 98.96800825593395\n",
      "Test set: Average loss: 0.0360, Test accuracy: 2784 / 5000 (56%)\n",
      "\n",
      "Communication Round 4\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.096882, Train accuracy: 94.56635318704284\n",
      "Train Epoch: 2 Loss: 0.033717, Train accuracy: 95.71577847439916\n",
      "Train Epoch: 3 Loss: 0.040881, Train accuracy: 96.02925809822362\n",
      "Train Epoch: 4 Loss: 0.014692, Train accuracy: 97.3876698014629\n",
      "Train Epoch: 5 Loss: 0.028976, Train accuracy: 97.59665621734587\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.013632, Train accuracy: 98.76308277830637\n",
      "Train Epoch: 2 Loss: 0.010523, Train accuracy: 98.76308277830637\n",
      "Train Epoch: 3 Loss: 0.003476, Train accuracy: 99.14367269267365\n",
      "Train Epoch: 4 Loss: 0.006072, Train accuracy: 99.23882017126546\n",
      "Train Epoch: 5 Loss: 0.000902, Train accuracy: 99.61941008563274\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.014760, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 2 Loss: 0.016384, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 3 Loss: 0.029150, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 4 Loss: 0.007049, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.006516, Train accuracy: 99.8080614203455\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.275493, Train accuracy: 84.09785932721712\n",
      "Train Epoch: 2 Loss: 0.069060, Train accuracy: 95.71865443425077\n",
      "Train Epoch: 3 Loss: 0.067776, Train accuracy: 96.43221202854231\n",
      "Train Epoch: 4 Loss: 0.095854, Train accuracy: 96.94189602446484\n",
      "Train Epoch: 5 Loss: 0.018081, Train accuracy: 97.14576962283384\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.075411, Train accuracy: 98.65841073271415\n",
      "Train Epoch: 2 Loss: 0.097291, Train accuracy: 98.76160990712074\n",
      "Train Epoch: 3 Loss: 0.066994, Train accuracy: 98.96800825593395\n",
      "Train Epoch: 4 Loss: 0.027480, Train accuracy: 98.96800825593395\n",
      "Train Epoch: 5 Loss: 0.021108, Train accuracy: 98.96800825593395\n",
      "Test set: Average loss: 0.0301, Test accuracy: 3216 / 5000 (64%)\n",
      "\n",
      "Communication Round 5\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.120358, Train accuracy: 95.40229885057471\n",
      "Train Epoch: 2 Loss: 0.053614, Train accuracy: 96.55172413793103\n",
      "Train Epoch: 3 Loss: 0.088206, Train accuracy: 96.34273772204807\n",
      "Train Epoch: 4 Loss: 0.161550, Train accuracy: 96.55172413793103\n",
      "Train Epoch: 5 Loss: 0.051538, Train accuracy: 97.59665621734587\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.049751, Train accuracy: 97.2407231208373\n",
      "Train Epoch: 2 Loss: 0.011712, Train accuracy: 99.23882017126546\n",
      "Train Epoch: 3 Loss: 0.003053, Train accuracy: 99.52426260704091\n",
      "Train Epoch: 4 Loss: 0.001602, Train accuracy: 99.61941008563274\n",
      "Train Epoch: 5 Loss: 0.002952, Train accuracy: 99.61941008563274\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.014234, Train accuracy: 99.52015355086372\n",
      "Train Epoch: 2 Loss: 0.008693, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 3 Loss: 0.014917, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 4 Loss: 0.015340, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.151095, Train accuracy: 99.71209213051823\n",
      "Training client 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Loss: 0.129540, Train accuracy: 95.20897043832824\n",
      "Train Epoch: 2 Loss: 0.158031, Train accuracy: 96.12640163098878\n",
      "Train Epoch: 3 Loss: 0.103849, Train accuracy: 96.73802242609582\n",
      "Train Epoch: 4 Loss: 0.052517, Train accuracy: 96.43221202854231\n",
      "Train Epoch: 5 Loss: 0.015764, Train accuracy: 96.73802242609582\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.058361, Train accuracy: 97.83281733746131\n",
      "Train Epoch: 2 Loss: 0.064184, Train accuracy: 98.76160990712074\n",
      "Train Epoch: 3 Loss: 0.020260, Train accuracy: 99.07120743034056\n",
      "Train Epoch: 4 Loss: 0.014543, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 5 Loss: 0.102260, Train accuracy: 97.52321981424149\n",
      "Test set: Average loss: 0.0264, Test accuracy: 3271 / 5000 (65%)\n",
      "\n",
      "Communication Round 6\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.171650, Train accuracy: 95.40229885057471\n",
      "Train Epoch: 2 Loss: 0.066613, Train accuracy: 94.14838035527691\n",
      "Train Epoch: 3 Loss: 0.027831, Train accuracy: 96.1337513061651\n",
      "Train Epoch: 4 Loss: 0.040410, Train accuracy: 97.80564263322884\n",
      "Train Epoch: 5 Loss: 0.019338, Train accuracy: 97.91013584117033\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.002111, Train accuracy: 98.8582302568982\n",
      "Train Epoch: 2 Loss: 0.002973, Train accuracy: 99.33396764985729\n",
      "Train Epoch: 3 Loss: 0.000101, Train accuracy: 99.52426260704091\n",
      "Train Epoch: 4 Loss: 0.000797, Train accuracy: 99.52426260704091\n",
      "Train Epoch: 5 Loss: 0.000250, Train accuracy: 99.52426260704091\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.005670, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 2 Loss: 0.005145, Train accuracy: 99.61612284069098\n",
      "Train Epoch: 3 Loss: 0.003554, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 4 Loss: 0.012674, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.005833, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.118549, Train accuracy: 96.53414882772681\n",
      "Train Epoch: 2 Loss: 0.191338, Train accuracy: 96.12640163098878\n",
      "Train Epoch: 3 Loss: 0.183251, Train accuracy: 96.73802242609582\n",
      "Train Epoch: 4 Loss: 0.076115, Train accuracy: 98.0632008154944\n",
      "Train Epoch: 5 Loss: 0.222399, Train accuracy: 96.2283384301733\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.117819, Train accuracy: 95.76883384932921\n",
      "Train Epoch: 2 Loss: 0.021711, Train accuracy: 98.86480908152735\n",
      "Train Epoch: 3 Loss: 0.017924, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 4 Loss: 0.010487, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 5 Loss: 0.072082, Train accuracy: 98.76160990712074\n",
      "Test set: Average loss: 0.0238, Test accuracy: 3443 / 5000 (69%)\n",
      "\n",
      "Communication Round 7\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.485668, Train accuracy: 95.71577847439916\n",
      "Train Epoch: 2 Loss: 0.033721, Train accuracy: 97.17868338557994\n",
      "Train Epoch: 3 Loss: 0.048703, Train accuracy: 97.70114942528735\n",
      "Train Epoch: 4 Loss: 0.040944, Train accuracy: 97.59665621734587\n",
      "Train Epoch: 5 Loss: 0.061167, Train accuracy: 97.17868338557994\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.008412, Train accuracy: 99.4291151284491\n",
      "Train Epoch: 2 Loss: 0.000566, Train accuracy: 99.23882017126546\n",
      "Train Epoch: 3 Loss: 0.000042, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 4 Loss: 0.000995, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 5 Loss: 0.000456, Train accuracy: 99.71455756422455\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.014000, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 2 Loss: 0.007365, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 3 Loss: 0.003820, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 4 Loss: 0.003815, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.002255, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.080503, Train accuracy: 96.73802242609582\n",
      "Train Epoch: 2 Loss: 0.064598, Train accuracy: 97.45158002038735\n",
      "Train Epoch: 3 Loss: 0.132923, Train accuracy: 97.96126401630988\n",
      "Train Epoch: 4 Loss: 0.055044, Train accuracy: 97.34964322120285\n",
      "Train Epoch: 5 Loss: 0.104232, Train accuracy: 95.82059123343527\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.035728, Train accuracy: 99.07120743034056\n",
      "Train Epoch: 2 Loss: 0.022558, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 3 Loss: 0.157077, Train accuracy: 96.28482972136223\n",
      "Train Epoch: 4 Loss: 0.021279, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 5 Loss: 0.010770, Train accuracy: 99.48400412796698\n",
      "Test set: Average loss: 0.0219, Test accuracy: 3485 / 5000 (70%)\n",
      "\n",
      "Communication Round 8\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.068135, Train accuracy: 95.92476489028213\n",
      "Train Epoch: 2 Loss: 0.005583, Train accuracy: 96.34273772204807\n",
      "Train Epoch: 3 Loss: 0.100019, Train accuracy: 97.4921630094044\n",
      "Train Epoch: 4 Loss: 0.035530, Train accuracy: 98.11912225705329\n",
      "Train Epoch: 5 Loss: 0.021800, Train accuracy: 98.11912225705329\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000264, Train accuracy: 99.33396764985729\n",
      "Train Epoch: 2 Loss: 0.000498, Train accuracy: 99.61941008563274\n",
      "Train Epoch: 3 Loss: 0.001503, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 4 Loss: 0.000525, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 5 Loss: 0.000516, Train accuracy: 99.80970504281636\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.012825, Train accuracy: 99.71209213051823\n",
      "Train Epoch: 2 Loss: 0.007007, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 3 Loss: 0.003579, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 4 Loss: 0.006083, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.005850, Train accuracy: 99.8080614203455\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.116942, Train accuracy: 97.75739041794088\n",
      "Train Epoch: 2 Loss: 0.101193, Train accuracy: 97.85932721712538\n",
      "Train Epoch: 3 Loss: 0.129571, Train accuracy: 98.1651376146789\n",
      "Train Epoch: 4 Loss: 0.027528, Train accuracy: 98.2670744138634\n",
      "Train Epoch: 5 Loss: 0.118106, Train accuracy: 96.53414882772681\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.013718, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 2 Loss: 0.010368, Train accuracy: 99.27760577915377\n",
      "Train Epoch: 3 Loss: 0.007742, Train accuracy: 99.27760577915377\n",
      "Train Epoch: 4 Loss: 0.007162, Train accuracy: 99.27760577915377\n",
      "Train Epoch: 5 Loss: 0.008164, Train accuracy: 99.58720330237358\n",
      "Test set: Average loss: 0.0204, Test accuracy: 3580 / 5000 (72%)\n",
      "\n",
      "Communication Round 9\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.093449, Train accuracy: 92.8944618599791\n",
      "Train Epoch: 2 Loss: 0.217918, Train accuracy: 69.17450365726228\n",
      "Train Epoch: 3 Loss: 0.005298, Train accuracy: 97.91013584117033\n",
      "Train Epoch: 4 Loss: 0.012511, Train accuracy: 98.22361546499478\n",
      "Train Epoch: 5 Loss: 0.035421, Train accuracy: 98.22361546499478\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000710, Train accuracy: 99.52426260704091\n",
      "Train Epoch: 2 Loss: 0.006841, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 3 Loss: 0.000026, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 4 Loss: 0.000063, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 5 Loss: 0.004832, Train accuracy: 99.71455756422455\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.003846, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 2 Loss: 0.007178, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 3 Loss: 0.003037, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.003080, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.003694, Train accuracy: 99.8080614203455\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.049984, Train accuracy: 97.34964322120285\n",
      "Train Epoch: 2 Loss: 0.105395, Train accuracy: 94.90316004077472\n",
      "Train Epoch: 3 Loss: 0.051169, Train accuracy: 98.2670744138634\n",
      "Train Epoch: 4 Loss: 0.016857, Train accuracy: 98.36901121304791\n",
      "Train Epoch: 5 Loss: 0.093024, Train accuracy: 97.04383282364934\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.021609, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 2 Loss: 0.017979, Train accuracy: 99.27760577915377\n",
      "Train Epoch: 3 Loss: 0.008297, Train accuracy: 99.48400412796698\n",
      "Train Epoch: 4 Loss: 0.027663, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 5 Loss: 0.014284, Train accuracy: 99.58720330237358\n",
      "Test set: Average loss: 0.0192, Test accuracy: 3639 / 5000 (73%)\n",
      "\n",
      "Communication Round 10\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.012228, Train accuracy: 97.59665621734587\n",
      "Train Epoch: 2 Loss: 0.233120, Train accuracy: 77.22048066875654\n",
      "Train Epoch: 3 Loss: 0.028028, Train accuracy: 98.0146290491118\n",
      "Train Epoch: 4 Loss: 0.003321, Train accuracy: 98.11912225705329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Loss: 0.037062, Train accuracy: 98.22361546499478\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000979, Train accuracy: 99.61941008563274\n",
      "Train Epoch: 2 Loss: 0.001311, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 3 Loss: 0.000327, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 4 Loss: 0.003564, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 5 Loss: 0.006787, Train accuracy: 99.80970504281636\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.019415, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 2 Loss: 0.004076, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 3 Loss: 0.002170, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.002013, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.002633, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.084444, Train accuracy: 98.2670744138634\n",
      "Train Epoch: 2 Loss: 0.045056, Train accuracy: 98.36901121304791\n",
      "Train Epoch: 3 Loss: 0.124499, Train accuracy: 96.94189602446484\n",
      "Train Epoch: 4 Loss: 0.058047, Train accuracy: 98.36901121304791\n",
      "Train Epoch: 5 Loss: 0.047439, Train accuracy: 98.77675840978593\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.016091, Train accuracy: 99.38080495356037\n",
      "Train Epoch: 2 Loss: 0.022214, Train accuracy: 99.48400412796698\n",
      "Train Epoch: 3 Loss: 0.087565, Train accuracy: 94.73684210526316\n",
      "Train Epoch: 4 Loss: 0.032391, Train accuracy: 99.17440660474716\n",
      "Train Epoch: 5 Loss: 0.018393, Train accuracy: 99.48400412796698\n",
      "Test set: Average loss: 0.0182, Test accuracy: 3671 / 5000 (73%)\n",
      "\n",
      "Communication Round 11\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.489550, Train accuracy: 70.53291536050156\n",
      "Train Epoch: 2 Loss: 0.006438, Train accuracy: 98.22361546499478\n",
      "Train Epoch: 3 Loss: 0.019862, Train accuracy: 98.43260188087774\n",
      "Train Epoch: 4 Loss: 0.361286, Train accuracy: 82.86311389759666\n",
      "Train Epoch: 5 Loss: 0.063287, Train accuracy: 97.70114942528735\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000531, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 2 Loss: 0.006020, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 3 Loss: 0.029805, Train accuracy: 99.33396764985729\n",
      "Train Epoch: 4 Loss: 0.000302, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 5 Loss: 0.000016, Train accuracy: 99.80970504281636\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.010280, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 2 Loss: 0.120779, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 3 Loss: 0.001647, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.002008, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.106374, Train accuracy: 99.8080614203455\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.119121, Train accuracy: 97.55351681957187\n",
      "Train Epoch: 2 Loss: 0.060321, Train accuracy: 97.55351681957187\n",
      "Train Epoch: 3 Loss: 0.028822, Train accuracy: 97.55351681957187\n",
      "Train Epoch: 4 Loss: 0.056341, Train accuracy: 98.47094801223241\n",
      "Train Epoch: 5 Loss: 0.055626, Train accuracy: 98.57288481141693\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.169077, Train accuracy: 93.3952528379773\n",
      "Train Epoch: 2 Loss: 0.028904, Train accuracy: 99.48400412796698\n",
      "Train Epoch: 3 Loss: 0.003799, Train accuracy: 99.48400412796698\n",
      "Train Epoch: 4 Loss: 0.067638, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 5 Loss: 0.001494, Train accuracy: 99.79360165118679\n",
      "Test set: Average loss: 0.0173, Test accuracy: 3732 / 5000 (75%)\n",
      "\n",
      "Communication Round 12\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.013832, Train accuracy: 97.4921630094044\n",
      "Train Epoch: 2 Loss: 0.033206, Train accuracy: 98.11912225705329\n",
      "Train Epoch: 3 Loss: 0.017948, Train accuracy: 97.59665621734587\n",
      "Train Epoch: 4 Loss: 0.004819, Train accuracy: 98.22361546499478\n",
      "Train Epoch: 5 Loss: 0.006552, Train accuracy: 98.53709508881923\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000092, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 2 Loss: 0.002996, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 3 Loss: 0.005760, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 4 Loss: 0.073207, Train accuracy: 98.66793529971456\n",
      "Train Epoch: 5 Loss: 0.006385, Train accuracy: 100.0\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.027570, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.001532, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 3 Loss: 0.003327, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.001937, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.002101, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.024407, Train accuracy: 97.75739041794088\n",
      "Train Epoch: 2 Loss: 0.104924, Train accuracy: 98.36901121304791\n",
      "Train Epoch: 3 Loss: 0.059036, Train accuracy: 97.34964322120285\n",
      "Train Epoch: 4 Loss: 0.047446, Train accuracy: 98.77675840978593\n",
      "Train Epoch: 5 Loss: 0.045817, Train accuracy: 98.87869520897044\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.007617, Train accuracy: 99.58720330237358\n",
      "Train Epoch: 2 Loss: 0.021527, Train accuracy: 99.69040247678019\n",
      "Train Epoch: 3 Loss: 0.015049, Train accuracy: 99.69040247678019\n",
      "Train Epoch: 4 Loss: 0.049601, Train accuracy: 99.07120743034056\n",
      "Train Epoch: 5 Loss: 0.053242, Train accuracy: 99.69040247678019\n",
      "Test set: Average loss: 0.0164, Test accuracy: 3773 / 5000 (75%)\n",
      "\n",
      "Communication Round 13\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.029792, Train accuracy: 98.43260188087774\n",
      "Train Epoch: 2 Loss: 0.133284, Train accuracy: 95.92476489028213\n",
      "Train Epoch: 3 Loss: 0.003972, Train accuracy: 98.53709508881923\n",
      "Train Epoch: 4 Loss: 0.031424, Train accuracy: 98.22361546499478\n",
      "Train Epoch: 5 Loss: 0.014731, Train accuracy: 98.74608150470219\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000108, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 2 Loss: 0.003096, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 3 Loss: 0.000037, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 4 Loss: 0.000365, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 5 Loss: 0.000113, Train accuracy: 100.0\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.001982, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.004090, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 3 Loss: 0.002230, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 4 Loss: 0.002249, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 5 Loss: 0.002132, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.015624, Train accuracy: 98.47094801223241\n",
      "Train Epoch: 2 Loss: 0.100014, Train accuracy: 98.77675840978593\n",
      "Train Epoch: 3 Loss: 0.042546, Train accuracy: 98.98063200815494\n",
      "Train Epoch: 4 Loss: 0.021994, Train accuracy: 98.98063200815494\n",
      "Train Epoch: 5 Loss: 0.015984, Train accuracy: 98.98063200815494\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.022940, Train accuracy: 98.96800825593395\n",
      "Train Epoch: 2 Loss: 0.007921, Train accuracy: 99.48400412796698\n",
      "Train Epoch: 3 Loss: 0.006494, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 4 Loss: 0.008990, Train accuracy: 99.69040247678019\n",
      "Train Epoch: 5 Loss: 0.012386, Train accuracy: 99.79360165118679\n",
      "Test set: Average loss: 0.0160, Test accuracy: 3775 / 5000 (76%)\n",
      "\n",
      "Communication Round 14\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.003953, Train accuracy: 97.91013584117033\n",
      "Train Epoch: 2 Loss: 0.005780, Train accuracy: 98.0146290491118\n",
      "Train Epoch: 3 Loss: 0.001739, Train accuracy: 98.64158829676072\n",
      "Train Epoch: 4 Loss: 0.003006, Train accuracy: 98.85057471264368\n",
      "Train Epoch: 5 Loss: 0.009131, Train accuracy: 98.74608150470219\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.007637, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 2 Loss: 0.007193, Train accuracy: 99.71455756422455\n",
      "Train Epoch: 3 Loss: 0.019961, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 4 Loss: 0.000156, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 5 Loss: 0.000002, Train accuracy: 99.80970504281636\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.020529, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.006027, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 3 Loss: 0.003543, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.001570, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.003999, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.034139, Train accuracy: 98.57288481141693\n",
      "Train Epoch: 2 Loss: 0.041657, Train accuracy: 98.87869520897044\n",
      "Train Epoch: 3 Loss: 0.007168, Train accuracy: 98.2670744138634\n",
      "Train Epoch: 4 Loss: 0.036763, Train accuracy: 98.47094801223241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Loss: 0.011101, Train accuracy: 99.28644240570846\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.057298, Train accuracy: 99.27760577915377\n",
      "Train Epoch: 2 Loss: 0.003469, Train accuracy: 99.48400412796698\n",
      "Train Epoch: 3 Loss: 0.015953, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 4 Loss: 0.007988, Train accuracy: 99.58720330237358\n",
      "Train Epoch: 5 Loss: 0.016469, Train accuracy: 99.8968008255934\n",
      "Test set: Average loss: 0.0152, Test accuracy: 3816 / 5000 (76%)\n",
      "\n",
      "Communication Round 15\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.038467, Train accuracy: 93.31243469174504\n",
      "Train Epoch: 2 Loss: 0.009773, Train accuracy: 98.43260188087774\n",
      "Train Epoch: 3 Loss: 0.025895, Train accuracy: 98.53709508881923\n",
      "Train Epoch: 4 Loss: 0.010914, Train accuracy: 98.64158829676072\n",
      "Train Epoch: 5 Loss: 0.001483, Train accuracy: 98.85057471264368\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.072770, Train accuracy: 95.71836346336822\n",
      "Train Epoch: 2 Loss: 0.001184, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 3 Loss: 0.000385, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 4 Loss: 0.000010, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 5 Loss: 0.001039, Train accuracy: 100.0\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.002124, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 2 Loss: 0.003078, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 3 Loss: 0.000913, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.000821, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.010053, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.048165, Train accuracy: 98.67482161060143\n",
      "Train Epoch: 2 Loss: 0.048493, Train accuracy: 98.87869520897044\n",
      "Train Epoch: 3 Loss: 0.054401, Train accuracy: 98.98063200815494\n",
      "Train Epoch: 4 Loss: 0.028310, Train accuracy: 98.36901121304791\n",
      "Train Epoch: 5 Loss: 0.014287, Train accuracy: 98.98063200815494\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.007027, Train accuracy: 99.69040247678019\n",
      "Train Epoch: 2 Loss: 0.111794, Train accuracy: 97.6264189886481\n",
      "Train Epoch: 3 Loss: 0.024005, Train accuracy: 99.48400412796698\n",
      "Train Epoch: 4 Loss: 0.003429, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 5 Loss: 0.002658, Train accuracy: 99.8968008255934\n",
      "Test set: Average loss: 0.0150, Test accuracy: 3839 / 5000 (77%)\n",
      "\n",
      "Communication Round 16\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.013723, Train accuracy: 98.64158829676072\n",
      "Train Epoch: 2 Loss: 0.007358, Train accuracy: 98.74608150470219\n",
      "Train Epoch: 3 Loss: 0.186779, Train accuracy: 59.665621734587255\n",
      "Train Epoch: 4 Loss: 0.116945, Train accuracy: 93.31243469174504\n",
      "Train Epoch: 5 Loss: 0.001175, Train accuracy: 98.64158829676072\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000377, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 2 Loss: 0.000864, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 3 Loss: 0.006647, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 4 Loss: 0.000962, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 5 Loss: 0.000864, Train accuracy: 99.80970504281636\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.004666, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.003631, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 3 Loss: 0.002188, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 4 Loss: 0.000635, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.001584, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.040517, Train accuracy: 99.18450560652396\n",
      "Train Epoch: 2 Loss: 0.012286, Train accuracy: 98.87869520897044\n",
      "Train Epoch: 3 Loss: 0.036305, Train accuracy: 99.08256880733946\n",
      "Train Epoch: 4 Loss: 0.021524, Train accuracy: 98.36901121304791\n",
      "Train Epoch: 5 Loss: 0.029926, Train accuracy: 98.47094801223241\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.006172, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 2 Loss: 0.003768, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 3 Loss: 0.006851, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 4 Loss: 0.016706, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 5 Loss: 0.023942, Train accuracy: 99.79360165118679\n",
      "Test set: Average loss: 0.0145, Test accuracy: 3874 / 5000 (77%)\n",
      "\n",
      "Communication Round 17\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.023425, Train accuracy: 98.74608150470219\n",
      "Train Epoch: 2 Loss: 0.086165, Train accuracy: 96.55172413793103\n",
      "Train Epoch: 3 Loss: 0.234312, Train accuracy: 51.93312434691745\n",
      "Train Epoch: 4 Loss: 0.040410, Train accuracy: 98.64158829676072\n",
      "Train Epoch: 5 Loss: 0.035805, Train accuracy: 98.64158829676072\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000499, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 2 Loss: 0.000034, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 3 Loss: 0.000068, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 4 Loss: 0.002463, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 5 Loss: 0.001355, Train accuracy: 100.0\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.001598, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.001960, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 3 Loss: 0.003699, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.001114, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.001862, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.003710, Train accuracy: 99.08256880733946\n",
      "Train Epoch: 2 Loss: 0.002327, Train accuracy: 98.98063200815494\n",
      "Train Epoch: 3 Loss: 0.032490, Train accuracy: 99.08256880733946\n",
      "Train Epoch: 4 Loss: 0.032587, Train accuracy: 98.77675840978593\n",
      "Train Epoch: 5 Loss: 0.009946, Train accuracy: 99.28644240570846\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.005167, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 2 Loss: 0.023293, Train accuracy: 99.38080495356037\n",
      "Train Epoch: 3 Loss: 0.006922, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 4 Loss: 0.023634, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 5 Loss: 0.000849, Train accuracy: 99.8968008255934\n",
      "Test set: Average loss: 0.0142, Test accuracy: 3906 / 5000 (78%)\n",
      "\n",
      "Communication Round 18\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.008127, Train accuracy: 98.64158829676072\n",
      "Train Epoch: 2 Loss: 0.073313, Train accuracy: 97.59665621734587\n",
      "Train Epoch: 3 Loss: 0.012687, Train accuracy: 98.85057471264368\n",
      "Train Epoch: 4 Loss: 0.037750, Train accuracy: 98.95506792058517\n",
      "Train Epoch: 5 Loss: 0.005856, Train accuracy: 98.95506792058517\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.003365, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 2 Loss: 0.000015, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 3 Loss: 0.000049, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 4 Loss: 0.001036, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 5 Loss: 0.053991, Train accuracy: 99.80970504281636\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.001695, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.001392, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 3 Loss: 0.003180, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 4 Loss: 0.000715, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.003293, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.021684, Train accuracy: 99.18450560652396\n",
      "Train Epoch: 2 Loss: 0.007482, Train accuracy: 98.98063200815494\n",
      "Train Epoch: 3 Loss: 0.050227, Train accuracy: 99.38837920489297\n",
      "Train Epoch: 4 Loss: 0.008096, Train accuracy: 99.38837920489297\n",
      "Train Epoch: 5 Loss: 0.017504, Train accuracy: 99.49031600407747\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.009262, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 2 Loss: 0.005782, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 3 Loss: 0.026925, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 4 Loss: 0.001496, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 5 Loss: 0.006674, Train accuracy: 99.58720330237358\n",
      "Test set: Average loss: 0.0137, Test accuracy: 3924 / 5000 (78%)\n",
      "\n",
      "Communication Round 19\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.014051, Train accuracy: 98.74608150470219\n",
      "Train Epoch: 2 Loss: 0.005737, Train accuracy: 99.05956112852665\n",
      "Train Epoch: 3 Loss: 0.097080, Train accuracy: 97.3876698014629\n",
      "Train Epoch: 4 Loss: 0.068380, Train accuracy: 98.22361546499478\n",
      "Train Epoch: 5 Loss: 0.006091, Train accuracy: 99.16405433646813\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.000012, Train accuracy: 99.90485252140819\n",
      "Train Epoch: 2 Loss: 0.000433, Train accuracy: 100.0\n",
      "Train Epoch: 3 Loss: 0.000009, Train accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Loss: 0.000077, Train accuracy: 100.0\n",
      "Train Epoch: 5 Loss: 0.000104, Train accuracy: 100.0\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.003214, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.002337, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 3 Loss: 0.109276, Train accuracy: 99.8080614203455\n",
      "Train Epoch: 4 Loss: 0.007779, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 5 Loss: 0.002531, Train accuracy: 99.90403071017275\n",
      "Training client 3\n",
      "Train Epoch: 1 Loss: 0.033444, Train accuracy: 99.08256880733946\n",
      "Train Epoch: 2 Loss: 0.008208, Train accuracy: 98.87869520897044\n",
      "Train Epoch: 3 Loss: 0.068299, Train accuracy: 98.36901121304791\n",
      "Train Epoch: 4 Loss: 0.035421, Train accuracy: 98.57288481141693\n",
      "Train Epoch: 5 Loss: 0.014675, Train accuracy: 99.69418960244649\n",
      "Training client 4\n",
      "Train Epoch: 1 Loss: 0.006597, Train accuracy: 99.79360165118679\n",
      "Train Epoch: 2 Loss: 0.003055, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 3 Loss: 0.015711, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 4 Loss: 0.008931, Train accuracy: 99.8968008255934\n",
      "Train Epoch: 5 Loss: 0.001014, Train accuracy: 99.8968008255934\n",
      "Test set: Average loss: 0.0135, Test accuracy: 3945 / 5000 (79%)\n",
      "\n",
      "Communication Round 20\n",
      "Training client 0\n",
      "Train Epoch: 1 Loss: 0.000708, Train accuracy: 98.95506792058517\n",
      "Train Epoch: 2 Loss: 0.000799, Train accuracy: 99.05956112852665\n",
      "Train Epoch: 3 Loss: 0.000830, Train accuracy: 99.16405433646813\n",
      "Train Epoch: 4 Loss: 0.036928, Train accuracy: 98.53709508881923\n",
      "Train Epoch: 5 Loss: 0.024820, Train accuracy: 98.95506792058517\n",
      "Training client 1\n",
      "Train Epoch: 1 Loss: 0.003660, Train accuracy: 99.80970504281636\n",
      "Train Epoch: 2 Loss: 0.000012, Train accuracy: 100.0\n",
      "Train Epoch: 3 Loss: 0.000003, Train accuracy: 100.0\n",
      "Train Epoch: 4 Loss: 0.000000, Train accuracy: 100.0\n",
      "Train Epoch: 5 Loss: 0.000080, Train accuracy: 100.0\n",
      "Training client 2\n",
      "Train Epoch: 1 Loss: 0.007150, Train accuracy: 99.90403071017275\n",
      "Train Epoch: 2 Loss: 0.001276, Train accuracy: 99.90403071017275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-016738df7894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training client {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#Average model parameters and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ma-2/optML_project/src/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(client, epoch, logging)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train Epoch: {epoch} Loss: {total_loss.item():.6f}, Train accuracy: {train_accuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ma-2/optML_project/src/training.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(client, logging)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/optML_project/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/optML_project/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/optML_project/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/optML_project/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/optML_project/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/optML_project/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/optML_project/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "testing_accuracy = 0\n",
    "bits_transferred = 0\n",
    "num_rounds = 0\n",
    "bits_conserved = 0\n",
    "\n",
    "centralServer = Client(test_loader)\n",
    "\n",
    "while testing_accuracy < ACCURACY_THRESHOLD:\n",
    "    num_rounds += 1\n",
    "    print(\"Communication Round {0}\".format(num_rounds))\n",
    "    \n",
    "    if num_rounds > 1:\n",
    "        #Load server weights onto clients\n",
    "        #TODO: Count number of transferred bits\n",
    "        for client in clients:\n",
    "            with torch.no_grad():\n",
    "                client.model.load_state_dict(dict(centralServer.model.named_parameters()))\n",
    "                \n",
    "    #Perform E local training steps for each client\n",
    "    for client_idx, client in enumerate(clients):\n",
    "        print(\"Training client {0}\".format(client_idx))\n",
    "        for epoch in range(1, client.epochs + 1):\n",
    "            train(client, epoch)\n",
    "\n",
    "    #Average model parameters and test\n",
    "    #TODO: Count number of transfered bits and sparsify gradients\n",
    "    with torch.no_grad():\n",
    "        dict_params = average_client_models(clients)\n",
    "        centralServer.model.load_state_dict(dict_params)\n",
    "    test_loss, testing_accuracy = test(centralServer)\n",
    "\n",
    "#Save model\n",
    "if centralServer.save_model:\n",
    "     torch.save(centralServer.model.state_dict(), f\"{centralServer.model_name}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
